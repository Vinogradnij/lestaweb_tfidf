# Веб-приложение для анализа tf и idf
## Описание
Веб-приложение, которое позволяет пользователю провести анализ текстовых 
документов на частоту слов в отдельно взятом документе (TF) 
и обратную частоту слов в коллекции документов (IDF).
## Использование
### Версия приложения - 0.1.0
### Веб-версия
* По адресу / доступна форма для загрузки пользовательских текстовых документов
### API
* **GET /** - вернет форму для загрузки файлов на сервер
* **POST /** - ожидает список файлов, вернет JSON ответ с результатми анализа
* **GET /status** - вернёт JSON вида {'status': 'OK'} при рабочем состоянии сервера
* **GET /version** - вернёт JSON вида {'version': version} с указанием версии приложения
## Реализация
### Используемые инструменты
* В качестве веб-фреймворка выбран FastAPI.
* В качестве базы данных используется PostgreSQL.
* Для работы с базой данных используется SQLAlchemy 2.0.
* Для управления миграциями используется Alembic.
* Для лемматизации слов используется pymorphy3.
* Для проверки на стоп-слово используется nltk.
### Алгоритм работы
1. Пользователь выбирает один или более файлов через форму загрузки, после чего файлы отправляются на сервер.
2. Экземпляр класса Analyzer начинает обход загруженных файлов построчно, где каждая строка очищается от лишних символов и разделяется на отдельные слова.
3. Каждое из слов приводится к нормальной форме (лемматизация) и проверяется на стоп-слово. 
4. После этого слово записывается в словарь в качестве экземпляра класса Word, либо если оно уже там присутствует, обновляются данные о нём.
5. При завершении обхода всех слов в файлах начинается обход составленного ранее словаря слов с целью подсчёта tf, idf.
6. Каждое "слово" (экземпляр класса Word) знает о том, сколько раз и в каких файлах оно встречается, поэтому расчёт происходит в экземпляре класса.
7. Результатом расчёта для одного слова является словарь, содержащий само слово, значения tf и idf. Результатом расчёта всех слов является список таких словарей.
8. После получения списка словарей он сортируется по уменьшению значения idf. Делается срез для первых 50 слов.
9. Подготовленный список значений передаётся веб-фреймворку, на основе которого создаётся веб-страница с отображением результата анализа.
### Описание структуры проекта
```
lestaweb_tfidf
├── src
│   ├── alembic
│   │   ├── versions
│   │   ├── env.py
│   │   └── script.py.mako
│   ├── tfidf
│   │   ├── files_handler.py
│   │   ├── models.py
│   │   ├── router.py
│   │   ├── schemas.py
│   │   └── service.py
│   ├── .gitignore
│   ├── .env-template
│   ├── alembic.ini
│   ├── config.py
│   ├── database.py
│   └── main.py
├── CHANGELOG.md
├── README.md
└── requirements.txt
```
* alembic/ - директория библиотеки alembic
  * version/ - директория хранения файлов миграции
  * env.py - настройка миграций
* tfidf/ - основная директория API приложения
  * files_handler.py - обработка пользовательских файлов
  * models.py - модели данных, используемых в API
  * router.py - обработка путей веб запросов API
  * schemas.py - Pydantic схемы данных API
  * service.py - бизнес логика обработки пользовательских запросов
* .gitignore - файл для указания git о том, что не следует индексировать
* .env-template - пример .env файла для конфигурации
* alembic.ini - настройка alembic
* config.py - конфигурационные настройки приложения
* database.py - управление соединением с БД
* main.py - точка входа в приложение
* CHANGELOG.md - описание изменений приложения согласно версионированию
* README.md - описание приложения, включая инструкции по настройке и запуску
* requirements.txt - зависимости приложения
## Подготовка к запуску
1. Клонировать репозиторий командой *git clone https://github.com/Vinogradnij/lestaweb_tfidf.git*
2. Создать виртуальное окружение (venv) для проекта и запустить его:
   * Необходимо перейти в корень проекта
   * Создать venv командой *python -m venv .venv*
   * Активировать venv 
     * Для Windows запустить скрипт: .venv\Scripts\activate.bat
     * Для Linux выполнить команду: source .venv/bin/activate
3. Установить зависимости для виртуальной среды проекта командой *pip install -r requirements.txt*
4. Запустить интерпретатор python и прописать:
   * import nltk
   * nltk.download('stopwords')
   * quit()
## Запуск
* Перейти в директорию src
* Выполнить команду: python main.py